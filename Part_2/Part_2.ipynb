{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Loading Data](#loading-data)\n",
    "* [Statistical Summary and Class Breakdown](#statistical-summary)\n",
    "* [Dropping Rows with Missing Values](#dropping-rows)\n",
    "* [Data Imputation](#data-imputation)\n",
    "* [Min-max Scaling](#min-max-scaling)\n",
    "* [standardization](#standardization)\n",
    "* [Robust Scaling](#robust-scaling)\n",
    "* [Categorical Data](#categorical-data)\n",
    "* [Feature Engineering](#feature-engineering)\n",
    "* [Univariate Selection](#univariate-selection)\n",
    "* [Recursive Feature Elimination](#recursive-feature-elimination)\n",
    "* [Dimensionality Reduction](#dimensionality-reduction)\n",
    "* [Hold-out Validation](#hold-out-validation)\n",
    "* [Cross Validation](#cross-validation)\n",
    "* [Confusion Matrix](#confusion-matrix)\n",
    "* [Classification Report](#classification-report)\n",
    "* [Grid Search](#grid-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "%matplotlib inline\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data <a class=\"anchor\" id=\"loading-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV file\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "# separate data into features and targets\n",
    "X = array[:,0:8]\n",
    "y = array[:,8]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Summary and Class Breakdown <a class=\"anchor\" id=\"statistical-summary\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print statistical summary and class breakdown\n",
    "from pandas import read_csv\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "print(df.shape) # print the dimension of the data\n",
    "print(df.describe()) # print the statistical summary of the data\n",
    "class_counts = df.groupby('class').size()\n",
    "print(class_counts) # print the class breakdown of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Rows with Missing Values <a class=\"anchor\" id=\"dropping-rows\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values by dropping data samples with missing values\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Age': [17, 23, 'x', 38, 54, 67, 32],\n",
    "                  'Height': [160, 172, 150, 165, 163, 158, 175],\n",
    "                  'Weight':[50, 68, 43, 52, 47, 49, 'x']})\n",
    "df.replace({'x': None}, inplace=True) # replace missing values (x) with NaN\n",
    "print(df)\n",
    "df.dropna(inplace=True) # drop rows with NaN\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation <a class=\"anchor\" id=\"data-imputation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Handling missing values by imputing missing values with statistic\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Age': [17, 23, 'x', 38, 54, 67, 32],\n",
    "                  'Height': [160, 172, 150, 165, 163, 158, 175],\n",
    "                  'Weight':[50, 68, 43, 52, 47, 49, 'x']})\n",
    "df.replace({'x': None}, inplace=True)\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True) # replace NaN with median\n",
    "df['Weight'].fillna(df['Weight'].mean(), inplace=True) # replace NaN with mean\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-max Scaling <a class=\"anchor\" id=\"min-max-scaling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data (between 0 and 1)\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "# separate array into input and output components\n",
    "X = array[:,:-1]\n",
    "y = array[:,-1]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(X)\n",
    "scaledX = scaler.transform(X)\n",
    "# Preview the scaled data\n",
    "print(scaledX[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization <a class=\"anchor\" id=\"standardization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data (0 mean, 1 stdev)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import read_csv\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "# separate array into input and output components\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "scaler = StandardScaler()\n",
    "scaledX = scaler.fit_transform(X)\n",
    "# Preview transformed data\n",
    "print(scaledX[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Scaling <a class=\"anchor\" id=\"robust-scaling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust scaling (0 median, 1 IQR)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from pandas import read_csv\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "# separate array into input and output components\n",
    "X = array[:,:-1]\n",
    "y = array[:,-1]\n",
    "scaler = RobustScaler()\n",
    "scaledX = scaler.fit_transform(X)\n",
    "# Preview transformed data\n",
    "print(scaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data <a class=\"anchor\" id=\"categorical-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling categorical data\n",
    "import pandas as pd\n",
    "df0 = pd.DataFrame({'year':[2015, 2017, 2013, 2018, 2020], \n",
    "                  'make':['Toyota', 'Honda', 'Perodua', 'Hyundai', 'Toyota'],\n",
    "                  'engine':[1.5, 1.8, 1.3, 1.6, 1.8],\n",
    "                  'review':['moderate', 'good', 'poor', 'moderate', 'good']})\n",
    "mapping = {'poor':1, 'moderate':2, 'good':3}\n",
    "df0['review'] = df0['review'].map(mapping) # encode ordinal data\n",
    "df0 = pd.get_dummies(df0) # encode nominal data\n",
    "print(df0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering <a class=\"anchor\" id=\"feature-engineering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create 2 new features\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "win_size = 3\n",
    "df['plas_pres'] = df['plas'] + df['pres'] # new feature 1\n",
    "df['mass_ave'] = df['mass'].rolling(win_size).mean() # new feature 2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Selection <a class=\"anchor\" id=\"univariate-selection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection with Univariate Selection\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "# load data\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "selector = SelectKBest(k=4)\n",
    "features = selector.fit_transform(X, y)\n",
    "selected = selector.get_support()\n",
    "# Show selected features\n",
    "print([names[i] for i in range(len(names)-1) if selected[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination <a class=\"anchor\" id=\"recursive-feature-elimination\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature Selection with RFE\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv(filename, names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "model = DecisionTreeClassifier()\n",
    "rfe = RFE(model, 3)\n",
    "features = rfe.fit_transform(X, y)\n",
    "selected = rfe.get_support()\n",
    "# Show selected features\n",
    "print([names[i] for i in range(len(names)-1) if selected[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction <a class=\"anchor\" id=\"dimensionality-reduction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction with PCA\n",
    "from pandas import read_csv\n",
    "from sklearn.decomposition import PCA\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "pca = PCA(n_components=3)\n",
    "features = pca.fit_transform(X)\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\" % pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-out Validation <a class=\"anchor\" id=\"hold-out-validation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using a train and a test set\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.33, random_state=42)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "result = model.score(X_test, y_test)\n",
    "print(f\"Accuracy: {100 * result:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation <a class=\"anchor\" id=\"cross-validation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate using Cross Validation\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = cross_val_score(model, X, y, cv=kfold)\n",
    "print(f\"Accuracy: {100*results.mean():.2f} % ({100*results.std():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix <a class=\"anchor\" id=\"confusion-matrix\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.33, random_state=42)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "plot_confusion_matrix(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report <a class=\"anchor\" id=\"classification-report\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classification report\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.33, random_state=42)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "report = ClassificationReport(model)\n",
    "report.score(X_test, y_test)\n",
    "report.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search <a class=\"anchor\" id=\"grid-search\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search for Hyperparameter Tuning\n",
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "params = dict(C=[0.001, 0.01, 0.1, 1, 10], gamma=[0.001, 0.01, 0.1, 1, 10])\n",
    "model = SVC()\n",
    "grid = GridSearchCV(model, params, n_jobs=-1, verbose=2)\n",
    "grid.fit(X, y)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
