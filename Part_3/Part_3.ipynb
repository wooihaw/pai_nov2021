{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Linear Regression](#linear-regression)\n",
    "* [Logistic Regression](#logistic-regression)\n",
    "* [kNN Classification](#knn-classification)\n",
    "* [Decision Tree Classification](#decision-tree-classification)\n",
    "* [Decision Tree Classification with Pruning](#decision-tree-classification-pruning)\n",
    "* [k-means Clustering](#k-means-clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "%matplotlib inline\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression <a class=\"anchor\" id=\"linear-regression\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.25, random_state=42)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "print(f'R2 score: {lr.score(X_test, y_test):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression <a class=\"anchor\" id=\"logistic-regression\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:,:-1]\n",
    "y = array[:,-1]\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.25, random_state=42)\n",
    "lgr = LogisticRegression().fit(X_train, y_train)\n",
    "print(f'Accuracy: {100 * lgr.score(X_test, y_test):.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Classification <a class=\"anchor\" id=\"knn-classification\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:,:-1]\n",
    "y = array[:,-1]\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.25, random_state=42)\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "print(f'Accuracy: {100 * knn.score(X_test, y_test):.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classification <a class=\"anchor\" id=\"decision-tree-classification\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:,:-1]\n",
    "y = array[:,-1]\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.25, random_state=42)\n",
    "dtc = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print(f'Train accuracy: {100 * dtc.score(X_train, y_train):.2f} %')\n",
    "print(f'Test accuracy: {100 * dtc.score(X_test, y_test):.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classification with Pruning<a class=\"anchor\" id=\"decision-tree-classification-pruning\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classification with pre-pruning\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:,:-1]\n",
    "y = array[:,-1]\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.25, random_state=42)\n",
    "dtc = DecisionTreeClassifier(max_leaf_nodes=10).fit(X_train, y_train)\n",
    "print(f'Train accuracy: {100 * dtc.score(X_train, y_train):.2f} %')\n",
    "print(f'Test accuracy: {100 * dtc.score(X_test, y_test):.2f} %')\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_tree(dtc, feature_names=names, class_names=['0', '1'], rounded=True, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means Clustering <a class=\"anchor\" id=\"k-means-clustering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "X, y = make_blobs(centers=3, cluster_std=2, random_state=42)\n",
    "km = KMeans(n_clusters=3).fit(X)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "fig.suptitle('k-means Clustering')\n",
    "ax1.scatter(X[:, 0], X[:, 1])\n",
    "ax1.set_title('Before clustering')\n",
    "ax2.scatter(X[:, 0], X[:, 1], c=km.labels_)\n",
    "ax2.set_title('After clustering')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
